{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gpt import GPT\n",
    "\n",
    "MODEL = 'gpt-3.5-turbo-0613'\n",
    "SECRET_KEY = os.getenv(\"GPT_SECRET_KEY\")\n",
    "TEMPERATURE = 0.7\n",
    "gpt_3_5 = GPT(MODEL,TEMPERATURE, SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "The training data contains 34,012 rows and 14 columns. The goal is to predict if there is a defect on the production line or not.\n",
    "The production line is modelled by the training data which contains the following variables.\n",
    "Predictor Variables: ['OP070_V_1_angle_value', 'OP090_SnapRingPeakForce_value',\n",
    "       'OP070_V_2_angle_value', 'OP120_Rodage_I_mesure_value',\n",
    "       'OP090_SnapRingFinalStroke_value', 'OP110_Vissage_M8_torque_value',\n",
    "       'OP100_Capuchon_insertion_mesure', 'OP120_Rodage_U_mesure_value',\n",
    "       'OP070_V_1_torque_value', 'OP090_StartLinePeakForce_value',\n",
    "       'OP110_Vissage_M8_angle_value', 'OP090_SnapRingMidPointForce_val',\n",
    "       'OP070_V_2_torque_value']\n",
    "Target Variable: 'Binar_OP130_Resultat_Global_v'\n",
    "Also note that the data has a class imbalance issue and the variables are on different numerical scales.\n",
    "\"\"\"\n",
    "query = \"\"\" \n",
    "Write a python code to train a classifier to predict if the device is faulty or not using the training data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To train a classifier to predict if the device is faulty or not, we can use various machine learning algorithms such as Logistic Regression, Random Forest, or Gradient Boosting. In this case, I will use the Random Forest algorithm.\n",
       "\n",
       "First, we need to import the necessary libraries and load the dataset:\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.ensemble import RandomForestClassifier\n",
       "from sklearn.metrics import classification_report, confusion_matrix\n",
       "\n",
       "# Load the dataset\n",
       "data = pd.read_csv('train_data.csv')\n",
       "```\n",
       "\n",
       "Next, we need to separate the predictor variables and the target variable:\n",
       "\n",
       "```python\n",
       "X = data.drop('Binar_OP130_Resultat_Global_v', axis=1) # Predictor variables\n",
       "y = data['Binar_OP130_Resultat_Global_v'] # Target variable\n",
       "```\n",
       "\n",
       "Since the data has a class imbalance issue, we can use the `class_weight` parameter in the Random Forest classifier to handle this imbalance:\n",
       "\n",
       "```python\n",
       "# Split the data into training and testing sets\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
       "\n",
       "# Train the Random Forest classifier\n",
       "classifier = RandomForestClassifier(class_weight='balanced')\n",
       "classifier.fit(X_train, y_train)\n",
       "```\n",
       "\n",
       "After training the classifier, we can make predictions on the test set and evaluate the performance of the model:\n",
       "\n",
       "```python\n",
       "# Make predictions on the test set\n",
       "y_pred = classifier.predict(X_test)\n",
       "\n",
       "# Evaluate the model\n",
       "print(confusion_matrix(y_test, y_pred))\n",
       "print(classification_report(y_test, y_pred))\n",
       "```\n",
       "\n",
       "For model evaluation, we can use metrics such as accuracy, precision, recall, and F1-score. The confusion matrix provides a summary of the predictions.\n",
       "\n",
       "Important things to note for model evaluation and deployment:\n",
       "\n",
       "1. Class imbalance: It is important to handle class imbalance issues, as it can affect the performance of the model. Techniques such as oversampling, undersampling, or using class weights can be used to address this issue.\n",
       "\n",
       "2. Feature scaling: Since the predictor variables are on different numerical scales, it is recommended to scale the features before training the model. This can be done using techniques such as standardization or normalization.\n",
       "\n",
       "3. Cross-validation: It is good practice to perform cross-validation to assess the generalization performance of the model. This helps to avoid overfitting and provides a more robust evaluation of the model's performance.\n",
       "\n",
       "4. Hyperparameter tuning: Random Forest has several hyperparameters that can be tuned to optimize the model's performance. Techniques such as grid search or random search can be used to find the best combination of hyperparameters.\n",
       "\n",
       "5. Model deployment: Once the model is trained and evaluated, it can be deployed in a production environment. This involves saving the trained model and creating an interface for making predictions on new data. It is important to monitor the model's performance and retrain it periodically to maintain accuracy."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "Given the context of the dataset and problem below, carry out the instruction below. Give an explanation for your choice of methods, libraries and algorithms. \n",
    "Also, provide a summary of important things to note for the next stage - {0}.\n",
    "\n",
    "Context:\n",
    "{1}\n",
    "\n",
    "Instruction:\n",
    "{2}\n",
    "\"\"\"\n",
    "\n",
    "prompt = prompt_template.format(context, query)\n",
    "gpt_3_5.query_gpt(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
