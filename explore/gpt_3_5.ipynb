{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gpt import GPT\n",
    "\n",
    "MODEL = 'gpt-3.5-turbo-0613'\n",
    "SECRET_KEY = os.getenv(\"GPT_SECRET_KEY\")\n",
    "TEMPERATURE = 0.5\n",
    "gpt_3_5 = GPT(MODEL,TEMPERATURE, SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Data cleaning, also known as data cleansing or data scrubbing, is the process of identifying and correcting or removing errors, inconsistencies, and inaccuracies in a dataset. It involves transforming raw data into a clean and reliable format that is suitable for analysis.\n",
       "\n",
       "Data cleaning is an essential step in the data preprocessing pipeline, as raw data often contains various issues that can negatively impact the quality and reliability of analytical results. These issues can include missing values, duplicate records, incorrect data types, outliers, spelling mistakes, inconsistent formatting, and more.\n",
       "\n",
       "The data cleaning process typically involves several tasks, such as:\n",
       "\n",
       "1. Handling missing data: This involves deciding how to deal with missing values, which can include imputation techniques, removing records with missing values, or creating a separate category for missing values.\n",
       "\n",
       "2. Removing duplicates: Identifying and removing duplicate records from the dataset to avoid redundancy and ensure data integrity.\n",
       "\n",
       "3. Correcting inconsistent data: This includes addressing inconsistencies in data formatting, such as inconsistent date formats or inconsistent units of measurement.\n",
       "\n",
       "4. Standardizing data: Converting data into a consistent format or unit of measurement to ensure consistency and comparability.\n",
       "\n",
       "5. Handling outliers: Identifying and addressing outliers, which are extreme values that deviate significantly from the rest of the data. Outliers can be removed, transformed, or treated separately depending on the specific analysis.\n",
       "\n",
       "6. Validating data integrity: Verifying the accuracy and integrity of data by performing various checks, such as cross-referencing with external sources or running logical checks on the data.\n",
       "\n",
       "By performing these data cleaning tasks, analysts can ensure that their dataset is accurate, complete, and consistent, which improves the reliability and validity of any subsequent data analysis or modeling."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = 'What is data cleaning?'\n",
    "gpt_3_5.query_gpt(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Here are some examples of Python code snippets to perform the data cleaning tasks mentioned earlier:\n",
       "\n",
       "1. Handling missing data:\n",
       "\n",
       "   - Removing records with missing values:\n",
       "     ```python\n",
       "     cleaned_data = original_data.dropna()\n",
       "     ```\n",
       "\n",
       "   - Imputing missing values using mean:\n",
       "     ```python\n",
       "     mean_value = original_data['column_name'].mean()\n",
       "     cleaned_data = original_data.fillna(mean_value)\n",
       "     ```\n",
       "\n",
       "2. Removing duplicates:\n",
       "   ```python\n",
       "   cleaned_data = original_data.drop_duplicates()\n",
       "   ```\n",
       "\n",
       "3. Correcting inconsistent data:\n",
       "   ```python\n",
       "   cleaned_data['date_column'] = pd.to_datetime(cleaned_data['date_column'], format='%Y-%m-%d')\n",
       "   ```\n",
       "\n",
       "4. Standardizing data:\n",
       "   ```python\n",
       "   cleaned_data['column_name'] = cleaned_data['column_name'].apply(lambda x: x.lower())\n",
       "   ```\n",
       "\n",
       "5. Handling outliers:\n",
       "   - Removing outliers using z-score:\n",
       "     ```python\n",
       "     from scipy import stats\n",
       "     z_scores = stats.zscore(original_data['column_name'])\n",
       "     threshold = 3\n",
       "     cleaned_data = original_data[(z_scores < threshold)]\n",
       "     ```\n",
       "\n",
       "   - Transforming outliers using winsorization:\n",
       "     ```python\n",
       "     from scipy.stats.mstats import winsorize\n",
       "     cleaned_data['column_name'] = winsorize(cleaned_data['column_name'], limits=[0.05, 0.05])\n",
       "     ```\n",
       "\n",
       "6. Validating data integrity:\n",
       "   - Cross-referencing with external source:\n",
       "     ```python\n",
       "     external_data = pd.read_csv('external_data.csv')\n",
       "     merged_data = pd.merge(cleaned_data, external_data, on='common_column', how='inner')\n",
       "     ```\n",
       "\n",
       "   - Running logical checks on data:\n",
       "     ```python\n",
       "     cleaned_data = cleaned_data[(cleaned_data['column_name'] >= 0) & (cleaned_data['column_name'] <= 100)]\n",
       "     ```\n",
       "\n",
       "Note: These code snippets are just examples, and you may need to adapt them based on your specific dataset and requirements. Additionally, you may need to import the necessary libraries, such as pandas and numpy, before running these code snippets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = 'Write python codes to perform the tasks you listed earlier.'\n",
    "gpt_3_5.query_gpt(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Determining which data cleaning tasks apply to your dataset depends on the specific characteristics and issues present in your data. Here are some steps you can follow to identify the tasks that may be relevant for your dataset:\n",
       "\n",
       "1. Explore the data: Start by getting familiar with your dataset. Look at the structure, format, and content of the data. Identify any potential issues or inconsistencies that you notice.\n",
       "\n",
       "2. Understand the data requirements: Consider the requirements of your analysis or the specific problem you are trying to solve. This will help you determine which data cleaning tasks are most relevant. For example, if you are performing time series analysis, correcting inconsistent date formats may be important. If you are building a predictive model, handling missing values and outliers might be crucial.\n",
       "\n",
       "3. Identify common data cleaning issues: Review common data cleaning issues and understand how they may apply to your dataset. Some common issues include missing values, duplicates, inconsistent formatting, outliers, and incorrect data types.\n",
       "\n",
       "4. Assess the quality of the data: Evaluate the quality and reliability of your dataset. Look for any indications of errors, inconsistencies, or inaccuracies. Consider factors such as data sources, data collection methods, and potential biases.\n",
       "\n",
       "5. Consult domain experts: If you have access to domain experts or subject matter experts in the specific field related to your dataset, consult with them. They can provide valuable insights into the data and help identify potential issues that may need to be addressed.\n",
       "\n",
       "6. Perform exploratory data analysis: Conduct exploratory data analysis (EDA) to gain a deeper understanding of your dataset. Visualize the data, calculate summary statistics, and identify any patterns or anomalies. This process can help you uncover data quality issues that need to be cleaned.\n",
       "\n",
       "By following these steps, you can gain a better understanding of the specific data cleaning tasks that are relevant for your dataset. Remember that data cleaning is often an iterative process, and you may need to revisit and refine your cleaning tasks as you gain more insights into the data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = 'How do I know which task applies to my dataset?'\n",
    "gpt_3_5.query_gpt(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! The code snippet provided under \"Handling Outliers\" demonstrates two common approaches to deal with outliers: removing outliers using z-score and transforming outliers using winsorization.\n",
       "\n",
       "1. Removing outliers using z-score:\n",
       "\n",
       "   ```python\n",
       "   from scipy import stats\n",
       "   z_scores = stats.zscore(original_data['column_name'])\n",
       "   threshold = 3\n",
       "   cleaned_data = original_data[(z_scores < threshold)]\n",
       "   ```\n",
       "\n",
       "   - First, we import the `stats` module from the `scipy` library, which provides statistical functions and tools.\n",
       "   - Next, we calculate the z-scores for the values in the specified column (`column_name`) of the original dataset. The z-score measures how many standard deviations a data point is away from the mean.\n",
       "   - We set a threshold value (e.g., 3) to determine what is considered an outlier. In this example, any data point with a z-score greater than the threshold is considered an outlier.\n",
       "   - Finally, we create a new dataset (`cleaned_data`) by selecting only the rows from the original dataset where the z-score is less than the threshold. This effectively removes the outliers from the dataset.\n",
       "\n",
       "2. Transforming outliers using winsorization:\n",
       "\n",
       "   ```python\n",
       "   from scipy.stats.mstats import winsorize\n",
       "   cleaned_data['column_name'] = winsorize(cleaned_data['column_name'], limits=[0.05, 0.05])\n",
       "   ```\n",
       "\n",
       "   - First, we import the `winsorize` function from the `scipy.stats.mstats` module, which provides a way to perform winsorization.\n",
       "   - We apply the winsorize function to the values in the specified column (`column_name`) of the cleaned dataset (`cleaned_data`).\n",
       "   - The `limits` parameter specifies the fraction of values to be trimmed from both the lower and upper ends of the distribution. In this example, 5% of the values from both ends of the distribution are replaced with the nearest non-outlier values.\n",
       "   - The winsorized values are then assigned back to the same column in the cleaned dataset.\n",
       "\n",
       "Both approaches provide different ways to handle outliers. Removing outliers entirely may be appropriate in some cases, while transforming them using winsorization can be useful when you want to retain the general shape of the distribution but reduce the impact of extreme values.\n",
       "\n",
       "It's important to note that the choice of approach depends on the specific characteristics of your dataset and the goals of your analysis. Additionally, you may need to adjust the threshold or limits values based on your data and requirements."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = 'Can you explain the code you shared under point 5: Handling Outliers?'\n",
    "gpt_3_5.query_gpt(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
